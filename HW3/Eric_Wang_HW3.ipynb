{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('HW3_training.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preping data for Linear and Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(200000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "# creates x and y variables\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "# split data into test and train\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates Linear Regression obj and runs predict on x_test\n",
    "lin_model = LinearRegression().fit(x_train,y_train)\n",
    "pred = lin_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the threshold to where I change isFraud to 0 or 1\n",
    "threshold=1\n",
    "indx = 0\n",
    "for i in range(len(x_test)):\n",
    "    # if isFraud = 1\n",
    "    if y_test.iloc[i] == 1:\n",
    "        # and the threshold is greater than prediction where isFraud = 1\n",
    "        if threshold >= pred[i] > 0:\n",
    "            threshold = pred[i] + (threshold/8)+0.02\n",
    "            indx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts to 0 or 1\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] >= threshold:\n",
    "        pred[i]=1\n",
    "    else:\n",
    "        pred[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(pred==y_test)/len(y_test))\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression is terrible at predicting fraud"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = LogisticRegression().fit(x_train,y_train)\n",
    "y_pred = logit_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(y_pred==y_test)/len(y_test))\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score and K value\n",
    "F1 = [0, -1]\n",
    "\n",
    "# tests different k neighbors and stores the best performing values\n",
    "for i in range(1, 12):\n",
    "    knn_model = KNeighborsClassifier(i)\n",
    "    knn_model.fit(x_train, y_train)\n",
    "    y_pred = knn_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(y_pred==y_test)/len(y_test))\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaling KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(200000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "#Rescaling features\n",
    "scaler=StandardScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# f1 score and K value\n",
    "F1 = [0, -1]\n",
    "\n",
    "# tests different k neighbors and stores the best performing values\n",
    "for i in range(1,12):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(y_pred==y_test)/len(y_test))\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robust Scaling KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(200000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "#Rescaling features\n",
    "scaler=RobustScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# f1 score and K value\n",
    "F1 = [0, -1]\n",
    "\n",
    "# tests different k neighbors and stores the best performing values\n",
    "for i in range(1, 12):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(y_pred==y_test)/len(y_test))\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMax KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(200000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "#Rescaling features\n",
    "scaler=MinMaxScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# f1 score and K value\n",
    "F1 = [0, -1]\n",
    "\n",
    "# tests different k neighbors and stores the best performing values\n",
    "for i in range(1, 12):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(y_pred==y_test)/len(y_test))\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxAbs Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(200000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "#Rescaling features\n",
    "scaler=MaxAbsScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# f1 score and K value\n",
    "F1 = [0, -1]\n",
    "\n",
    "# tests different k neighbors and stores the best performing values\n",
    "for i in range(1, 12):\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(x_train,y_train)\n",
    "    y_pred=knn.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sum(y_pred==y_test)/len(y_test))\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN with Robust Scaling yields the best performance with K = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/vc7g33x55zj491kqzxj0jdm80000gn/T/ipykernel_45024/984923542.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_model = df_model.append(fraud)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8372093023255814, 17]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(190000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "F1 = [0, -1]\n",
    "best_standard_model = None\n",
    "\n",
    "# tests different depths and stores the best performing values\n",
    "for i in range(1, 120):\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    tree_model = tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i\n",
    "        best_standard_model = tree_model\n",
    "\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robust Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/vc7g33x55zj491kqzxj0jdm80000gn/T/ipykernel_45024/1242992669.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_model = df_model.append(fraud)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8513119533527697, 19]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(170000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "\n",
    "scaler=RobustScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "F1 = [0, -1]\n",
    "best_robust_model = None\n",
    "\n",
    "# tests different depths and stores the best performing values\n",
    "for i in range(1, 120):\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    tree_model = tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i\n",
    "        best_robust_model = tree_model\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/vc7g33x55zj491kqzxj0jdm80000gn/T/ipykernel_45024/666238185.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_model = df_model.append(fraud)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8535825545171339, 93]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(175000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "F1 = [0, -1]\n",
    "best_MinMax_model = None\n",
    "\n",
    "# tests different depths and stores the best performing values\n",
    "for i in range(1, 120):\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    tree_model = tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i\n",
    "        best_MinMax_model = tree_model\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxAbs Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/vc7g33x55zj491kqzxj0jdm80000gn/T/ipykernel_45963/2015694723.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_model = df_model.append(fraud)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8680351906158359, 98]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(172000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "scaler=MaxAbsScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.185, random_state=52)\n",
    "\n",
    "F1 = [0, -1]\n",
    "best_MaxAbs_model = None\n",
    "\n",
    "# tests different depths and stores the best performing values\n",
    "for i in range(1, 120):\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    tree_model = tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i\n",
    "        best_MaxAbs_model = tree_model\n",
    "F1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/vc7g33x55zj491kqzxj0jdm80000gn/T/ipykernel_45963/4142744628.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_model = df_model.append(fraud)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.822429906542056, 68]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "# filters fraudulent observations\n",
    "fraud = df_model[df_model['isFraud'] == 1]\n",
    "# samples n observations from original data\n",
    "df_model = df_model.sample(168000)\n",
    "# removes those identical fraudulent data from df_model\n",
    "df_model = df_model[df_model['isFraud']==0]\n",
    "df_model = df_model.append(fraud)\n",
    "\n",
    "\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "F1 = [0, -1]\n",
    "best_model = None\n",
    "# tests different depths and stores the best performing values\n",
    "for i in range(1, 120):\n",
    "    tree_classifier = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    tree_model = tree_classifier.fit(x_train, y_train)\n",
    "    y_pred = tree_model.predict(x_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    if f1 > F1[0]:\n",
    "        F1[0] = f1\n",
    "        F1[1] = i\n",
    "        best_model = tree_model\n",
    "F1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the best model on HW3_test_input dataset\n",
    "\n",
    "#### Preprocessing; both standard and MaxAbs scaling methods yielded similar performing models, achieving f1 score~ 0.87 with 175000 random samples at its highest where 'isFraud' == 0 and the 912 observations where 'isFraud' == 1\n",
    "\n",
    "#### I think using MaxAbs model makes the most sense, so the saved prediction file is uses MaxAbs scaling with a decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('HW3_test_input.csv')\n",
    "\n",
    "df_model = test.copy()\n",
    "\n",
    "scaler=MaxAbsScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "\n",
    "y_test_pred = best_MaxAbs_model.predict(x)\n",
    "np.savetxt('/Users/ericwang/Desktop/ECON_148/HW3/maxAbsTree_prediction.csv',y_test_pred, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8337280909521555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "scaler=MaxAbsScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "x = df_model.drop(columns=['isFraud'])\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "\n",
    "f1_score(y, best_MaxAbs_model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = train.copy()\n",
    "\n",
    "scaler=MaxAbsScaler()\n",
    "features = [['amount','oldbalanceOrg','newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']]\n",
    "for feature in features:\n",
    "    df_model[feature] = scaler.fit_transform(df_model[feature])\n",
    "\n",
    "x = df_model\n",
    "x = pd.get_dummies(x, columns=['type'], drop_first=True) # create dummies\n",
    "y = df_model['isFraud']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "param = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [12,13,14,15,16,17,18,19],\n",
    "    \"splitter\": [\"best\", \"random\"]\n",
    "    }\n",
    "grid = GridSearchCV(clf, param_grid=param, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 12, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(x_train,y_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini',max_depth=12,splitter='best')\n",
    "tree_model = clf.fit(x_train, y_train)\n",
    "y_pred = tree_model.predict(x_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
